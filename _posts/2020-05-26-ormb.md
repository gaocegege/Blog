---
layout: post
title: "ormb：像管理 Docker 容器镜像一样管理机器学习模型"
description: 
headline:
modified: 2020-05-26
category: 
tags: []
imagefeature:
mathjax: false
chart:
comments: true
featured: true
---

> 才云科技计划于 2020 年开始，逐渐开源云原生机器学习平台 Clever 的社区版，机器学习模型管理组件 [ormb][] 是第一个开源的组件。它能够像管理容器镜像一样管理机器学习模型。
>
> 它不仅能够提供版本化的模型管理能力，还可以利用符合 OCI 标准的容器镜像仓库存储和分发机器学习模型。同时，通过 Harbor 2.0 还可实现在多个镜像仓库间的同步，满足更多企业级的需求。

以 Docker 为代表的容器虚拟化技术，业已成为云计算中的中流砥柱。世界各地的软件工程师们纷纷成为了它的拥趸。以 Open Container Initiative 作为基础，容器的生态迅速演化。Docker Compose，Kata Containers 等项目百花齐放，Kubernetes 更是成为了集群调度领域的事实标准。

回过头看，以 Docker 为代表的容器虚拟化技术，能够以雷霆万钧之势席卷世界，最大的依仗是它的镜像分发能力。这是其他技术一直以来不曾解决的问题，也是在应用部署场景一直以来的痛苦之处。Docker 把 Build Once, Deploy Anywhere 的能力带给了传统应用场景。

Java、NodeJS、Rust 等等各种各样的语言，各种各样的依赖库，都可以在本地一次构建成符合 OCI 规范的容器镜像，随后利用镜像仓库进行存储和分发。

Docker 很好地解决了传统应用分发的问题，那么在机器学习场景下，我们是否需要分发的能力？

## 为什么需要分发模型

机器学习场景与传统的应用场景相比，存在一定的差异，也正是这些差异导致了对分发能力的要求有一些偏差。在传统的应用场景下，需要分发的通常是二进制可执行程序，或者带有语言解释器的脚本代码，或者是带有语言的运行时或者虚拟机的字节码。而且，对于传统应用的场景，通常开发团队迭代的是代码，且同一个版本的代码多次编译出来的输出工件是一致的。

而在机器学习场景下，算法工程师在迭代开发的是模型（包括模型的结构和权重），以及对应的预处理后处理等相关逻辑等。同一版本的训练代码，根据输入的数据和随机状态（Random State）的不同，也会产生不同的模型。

因此，**在机器学习场景下，与其说我们想分发应用，不如说我们想分发的是模型**。

## State of the Art

在机器学习场景下，分发模型是我们关注的特性，这一特性也是不少开源项目想要提供的。目前在业界，这一问题主要有两种实现思路。

第一种是以 [Caicloud Clever Model Registry V1](https://caicloud.io/products/clever) 为代表的

另外一种，是以 [ModelDB](https://github.com/VertaAI/modeldb) 为代表的，

## 利用镜像仓库分发机器学习模型

在机器学习场景下，分发模型是我们关注的特性。[ormb][] 也正是为了解决这一问题实现的组件。[ormb][] 的名称源自 OCI-Based Registry for ML/DL Model Bundle，

## 与 Harbor 的集成

## 技术实现

[ormb]: https://github.com/caicloud/ormb

## License

- This article is licensed under [CC BY-NC-SA 3.0](https://creativecommons.org/licenses/by-nc-sa/3.0/).
- Please contact me for commercial use.
