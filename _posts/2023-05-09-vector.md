---
layout: post
title: "你真的需要一个（专门的）向量数据库么"
description: 
headline:
modified: 2023-05-09
category: 
tags: []
imagefeature:
mathjax: false
chart:
comments: true
featured: true
---

随着 LLM 的火爆，向量数据库也成为了一个热门的话题。只需要一些简单的 Python 代码，向量数据库就可以为你的 LLM 插上一个廉价但极有效的“外接大脑”。但是，我们是否真的需要一个专门的向量数据库呢？

##  LLM 为什么需要向量搜索？

首先，我来简单介绍一下 LLM 为什么需要用到向量搜索技术。向量搜索是一个非常有年头的问题了。给定一个对象，在一个集合中找到与它最相似的对象的过程，就是向量搜索。文本/图片等内容，都可以通过将其转换为向量的表示方式，进而将文本/图片的相似度问题转换为向量的相似度问题。

<figure>
	<img src="{{ site.url }}/images/vector/text.png" height="400" width="800">
    <figcaption>Text search (credit: https://docs.relevanceai.com/docs/what-is-vector-search)</figcaption>
</figure>

在上面的例子中，我们将不同的词语转换为一个三维的向量。因此我们可以在一个 3D 空间里直观的展示不同词语之间的相似度。例如，`student` 和 `school` 之间的相似度就比 `student` 和 `food` 之间的相似度更高。

回到 LLM 的场景里，模型的上下文（context）的长度限制是一个让人头疼的问题。比如 ChatGPT 3.5 的上下文长度限制在 4k tokens。LLM 最令人惊讶赞叹的能力之一就是 context-learning，这一限制很影响模型的使用体验。而向量搜索可以非常巧妙地绕过这一问题：

- 将超出上下文长度限制的文本划分成较短的 chunks，将不同的 chunks 转换为向量（embedding）。
- 在输入 prompt 到 LLM 之前，也将 prompt 转换为向量（embedding）。
- 将 prompt 向量进行搜索，寻找到最相似的 chunk 向量。
- 将最相似的 chunk 向量与 prompt 向量拼接，作为 LLM 的输入。

这样相当于我们给予了 LLM 一个外部的记忆，让它可以从这个记忆中搜索到最相关的信息。这个记忆就是向量搜索带来的能力。如果你想了解更多细节，可以阅读[这篇文章](https://simplicityissota.substack.com/p/what-is-an-embedding-anyways)和[这篇文章](https://betterprogramming.pub/enhancing-chatgpt-with-infinite-external-memory-using-vector-database-and-chatgpt-retrieval-plugin-b6f4ea16ab8)，他们比我解释地要清楚的多。

## 为什么向量数据库如此受欢迎？

在 LLM 中，向量数据库成为了必不可少的部分。最重要的原因之一是易用性。在配合 OpenAI Embedding 模型（如 `text-embedding-ada-002` 等）后只需要十行左右的代码，就可以实现将 prompt query 转换成向量，随后进行向量搜索的整个过程：

```python
def query(query, collection_name, top_k=20):

    # Creates embedding vector from user query
    embedded_query = openai.Embedding.create(
        input=query,
        model=EMBEDDING_MODEL,
    )["data"][0]['embedding']
    
    near_vector = {"vector": embedded_query}

    # Queries input schema with vectorized user query
    query_result = (
        client.query
        .get(collection_name)
        .with_near_vector(near_vector)
        .with_limit(top_k)
        .do()
    )
    
    return query_result
```

向量搜索在其中主要起到了召回的作用。通俗来讲，召回就是在候选集中找到最相近的一些对象。在 LLM 中，候选集就是所有的 chunks，而最相近的对象就是与 prompt 最相似的 chunk。向量搜索在 LLM 推理的过程中，被当做了最主要的召回的实现。它实现简单，并且可以借助 OpenAI Embedding 模型，解决最麻烦的文本转换为向量的问题。剩下的就是独立的向量搜索问题，目前的向量数据库都可以很好地解决这一问题。因此整个流程特别顺畅。

向量数据库，顾名思义，是专门为了向量这一特殊的数据类型设计的数据库。向量的相似度计算，是 O(n^2) 复杂度的问题，因为要两两比较集合中所有的向量。因此工业界提出了近似近邻（ANN）的算法。利用 ANN 的算法，通过预先计算的方式构建向量的索引，用空间换时间的思路，可以大大加快相似度计算的过程。这与传统的数据库的索引异曲同工。

这样一来，性能强，且易用性又好，与 LLM 真的是绝配！（吗？）

## 向量数据库的问题

前面介绍了非常多向量数据库的优势与好处，那么，它存在什么问题呢？[SingleStore 的博文](https://www.singlestore.com/blog/why-your-vector-database-should-not-be-a-vector-database/)珠玉在前，给出了一个很好的答案：

> Vectors and vector search are a data type and query processing approach, not a foundation for a new way of processing data. Using a specialty vector database (SVDB) will lead to the usual problems we see (and solve) again and again with our customers who use multiple specialty systems: redundant data, excessive data movement, lack of agreement on data values among distributed components, extra labor expense for specialized skills, extra licensing costs, limited query language power, programmability and extensibility, limited tool integration, and poor data integrity and availability compared with a true DBMS.

> 向量和向量搜索是一种数据类型和查询处理方法，而不是处理数据的新方法的基础。使用专业向量数据库(SVDB)将导致我们在使用多个专用数据库的客户中一次又一次看到(并解决)的常见问题:冗余数据、过度的数据搬运、分布式组件之间的数据缺乏一致性、专业技能的额外劳动力成本、额外的许可成本、有限的查询语言能力、可编程性和可扩展性、有限的工具集成、以及与真正的DBMS相比较差的数据完整性和可用性。

其中有三个问题是我觉得比较重要的。首先是数据一致性的问题。在进行原型实验的阶段，向量数据库非常合适，易用性战胜一切。但是向量数据库是一个独立的，与其他数据存储（如 TP 数据库，AP 数据湖等）完全解耦的系统。一致性问题是阿喀琉斯之踵，数据需要在多个系统之间同步、流转、处理。举个例子，假设用户的存量数据在 PostgresQL 中，而如果要使用向量数据库，就需要将数据首先转换成向量，然后再同步到专门的向量数据库中。历经取数、转换、同步等过程，数据的一致性就会受到很大的影响。

## 性能真的重要么？

## 重要的是什么？

## 以史为鉴：NoSQL

## References

- [Why Your Vector Database Should Not be a Vector Database](https://www.singlestore.com/blog/why-your-vector-database-should-not-be-a-vector-database/)
- [Do you actually need a vector database?](https://www.ethanrosenthal.com/2023/04/10/nn-vs-ann/)
- [What is vector search? - relevanceai.com](https://docs.relevanceai.com/docs/what-is-vector-search)

## License

- This article is licensed under [CC BY-NC-SA 3.0](https://creativecommons.org/licenses/by-nc-sa/3.0/).
- Please contact me for commercial use.
